akka {
  // log-config-on-start = on
  loglevel = debug
  log-dead-letters = on
  logger-startup-timeout = 30s

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    debug.unhandled = on
    allow-java-serialization = off

    # Use the "default" serialization for messages with not-yet-created event adapters
    serialization-bindings {
      "java.io.Serializable" = none
    }
  }
}


iotKafka{

  port = 8080
  port = ${?HTTP_LISTEN_PORT}
  interface = "0.0.0.0"
  interface = ${?HTTP_LISTEN_INTERFACE}

  delayForProducts = 7000
  delayForProducts = ${?DELAY_FOR_PRODUCTS}
  maxRetriesForProducts = 100
  maxRetriesForProducts = ${?MAX_RETRIES_FOR_PRODUCTS}


  kafka {
    schemaRegistryUrl = "http://192.168.1.182:8081"
    schemaRegistryUrl = ${?SCHEMAREGISTRY_URL}
    bootstrapServers = "192.168.1.182:9092"
    bootstrapServers = ${?KAFKA}
    storeBasePath = "docker/data"
    storeBasePath = ${?STORE_BASEPATH}
    replicationFactor = 1
    replicationFactor = ${?KAFKA_REPLICATION_FACTOR}
    producerMessagesAcknowledge = "all"
    producerMessagesAcknowledge = ${?KAFKA_PRODUCER_ACKS}
    enableConfluentInterceptors = false
    enableConfluentInterceptors = ${?ENABLE_CONFLUENT_INTERCEPTORS}


    kafkaEventConsumer {
      bootstrap.servers = ${iotKafka.kafka.bootstrapServers}
      enable.auto.commit = false
      max.poll.interval.ms = 90000
      max.poll.records = 30
      max.poll.records = ${?KAFKA_EVENT_CONSUMER_MAX_POLL_RECORDS}
      unconfirmed.timeout = 90 seconds
    }
  }
}